{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Machine Learning Algo to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load important libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.pandas.set_option('display.max_rows',None)\n",
    "pd.pandas.set_option('display.max_columns',None)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import EDA files \n",
    "df = pd.read_csv('Train_cleaned.csv')\n",
    "df_test = pd.read_csv('Test_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import original test file for storing appno which will be needed in submission file of the competition\n",
    "dx = pd.read_csv('test.csv')\n",
    "app_no_testdata = dx['appno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8878, 384)\n",
      "(4760, 383)\n"
     ]
    }
   ],
   "source": [
    "#Shape of the data\n",
    "print(df.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Preprocess data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label and target create\n",
    "\n",
    "X = df.drop('importance',axis=1).values\n",
    "y= df['importance'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8878, 383)\n",
      "(8878,)\n"
     ]
    }
   ],
   "source": [
    "#shape of X and y\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data in train and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set test set\n",
    "\n",
    "X1_test = df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale test set\n",
    "\n",
    "X1_test = scaler.transform(X1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import SVM and GridSearchCV\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use GridSearchCV for parameter tune\n",
    "\n",
    "# svc = SVC()\n",
    "# parameters = {\n",
    "#     'kernel': ['rbf','poly'], #######85,82.5\n",
    "#     'C': [0.1,0.5,1],\n",
    "#     'gamma': [0.001,0.01,0.1,1]\n",
    "# }\n",
    "\n",
    "# svc = SVC()\n",
    "# parameters = {\n",
    "#     'kernel': ['linear', 'rbf','poly','sigmoid'],\n",
    "#     'C': [0.1, 1]\n",
    "# }\n",
    "\n",
    "# cv_svm = GridSearchCV(svc, parameters, cv=5)\n",
    "# cv_svm.fit(X_train, y_train)\n",
    "\n",
    "# cv_svm.best_params_\n",
    "# {'C': 1, 'kernel': 'poly'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, gamma=0.1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the data with hyperparameter from GridSearch\n",
    "\n",
    "svc_model=SVC(C=1,kernel='rbf',gamma=0.1)\n",
    "svc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score 85.72072072072072\n",
      "Train Score 90.41754280564734\n"
     ]
    }
   ],
   "source": [
    "#Check the accuracy score\n",
    "\n",
    "pred_svc = svc_model.predict(X_test)\n",
    "print('Test Score', 100* accuracy_score(y_test,pred_svc))\n",
    "\n",
    "pred_actual = svc_model.predict(X_train)\n",
    "print('Train Score', 100* accuracy_score(y_train,pred_actual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got submission score- 82.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import Multinomial naive bayes\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tune\n",
    "\n",
    "# nb = MultinomialNB()\n",
    "# parameters = {\n",
    "#     'alpha': [4,3,2,1, 0.1, 0.01, 0.001]  \n",
    "# }\n",
    "# cv_nb = GridSearchCV(nb, parameters, cv=5)\n",
    "# cv_nb.fit(X_train, y_train)\n",
    "\n",
    "# cv_nb.best_params_\n",
    "#{'alpha': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 80.49549549549549\n",
      "Train Score 80.6848903574647\n"
     ]
    }
   ],
   "source": [
    "#fitting the data with hyperparameter from GridSearch\n",
    "#Check the accuracy score\n",
    "\n",
    "nb_model = MultinomialNB(alpha=4)\n",
    "nb_model.fit(X_train, y_train)\n",
    "pred_nb = nb_model.predict(X_test)\n",
    "print('Score', 100* accuracy_score(y_test,pred_nb))\n",
    "\n",
    "\n",
    "pred_actual = nb_model.predict(X_train)\n",
    "print('Train Score', 100* accuracy_score(y_train,pred_actual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs poorly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import RandomForest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tune\n",
    "\n",
    "# rf = RandomForestClassifier()\n",
    "# parameters = {\n",
    "#     'n_estimators': [100,200,300], \n",
    "#     'max_depth': [10,12,14],\n",
    "# }\n",
    "\n",
    "# cv_rf = GridSearchCV(rf, parameters, cv=5)\n",
    "# cv_rf.fit(X_train, y_train)\n",
    "\n",
    "# cv_rf.best_params_ #{'max_depth': 14, 'n_estimators': 300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=14, n_estimators=300)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the data with hyperparameter from GridSearch\n",
    "\n",
    "rf_model=RandomForestClassifier(n_estimators=300,max_depth=14)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 86.57657657657658\n",
      "Train Score 92.67047161309702\n"
     ]
    }
   ],
   "source": [
    "#Check the accuracy score\n",
    "\n",
    "pred_rf = rf_model.predict(X_test)\n",
    "print('Score', 100* accuracy_score(y_test,pred_rf))\n",
    "\n",
    "\n",
    "pred_actual = rf_model.predict(X_train)\n",
    "print('Train Score', 100* accuracy_score(y_train,pred_actual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got submission score- 84.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import xgboost classifier\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearch hyperparameter\n",
    "\n",
    "# xgb = XGBClassifier()\n",
    "# parameters = {\n",
    "#     'n_estimators': [200,300], \n",
    "#     'max_depth': [8,10,12],\n",
    "#     'learning_rate': [0.1,0.8],\n",
    "#     'reg_lambda':[1,0.1]\n",
    "# }\n",
    "\n",
    "# cv_xgb = GridSearchCV(xgb, parameters, cv=5)\n",
    "# cv_xgb.fit(X_train, y_train)\n",
    "\n",
    "# cv_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 88.51351351351352\n",
      "Score 98.81345749474316\n"
     ]
    }
   ],
   "source": [
    "#fitting the data with hyperparameter from GridSearch\n",
    "#Check the accuracy score\n",
    "\n",
    "\n",
    "xgb_model=XGBClassifier(n_estimators=200,max_depth=8,reg_lambda=1,learning_rate=0.1)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "pred_xgb = xgb_model.predict(X_test)\n",
    "print('Score', 100* accuracy_score(y_test,pred_xgb))\n",
    "\n",
    "pred_actual = xgb_model.predict(X_train)\n",
    "print('Score', 100* accuracy_score(y_train,pred_actual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As xgboost classifier has much higher accuracy, we select this model to predict the given test data for submission**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create final submission file with prediction from xgboost classifier\n",
    "\n",
    "pred_final = xgb_model.predict(X1_test)\n",
    "d_pred={'appno':app_no_testdata,'importance':pred_final}\n",
    "pred_csv = pd.DataFrame(d_pred)\n",
    "\n",
    "pred_csv.to_csv('prediction7.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
